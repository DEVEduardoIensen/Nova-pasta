

‚úÖ ESTRUTURA L√ìGICA DO PROJETO NEUROSCALP (v1.0 - TESTES)

üìå Objetivo:

Criar um sistema modular onde o GPT-4.1-mini recebe dados em tempo real da Binance (via WebSocket) e:

Analisa candles, fluxo de ordens e book.

Sugere entradas/sa√≠das automaticamente.

Ajusta os tempos dos dados (ms) quando quiser.

Se comunica com o operador humano como um s√≥cio.

pra opera√ßao quantidade de usdt e status da opera√ßao, nada alem disso.

---

üìÅ Estrutura de arquivos (oficial):

üìÇ projeto_neuroscalp
‚îú‚îÄ‚îÄ main.py                  # Onde o GPT decide "COMPRA", "VENDA", ou fica em sil√™ncio (execu√ß√£o futura)
‚îú‚îÄ‚îÄ envio_fluxo.py           # Envia apenas: pre√ßo atual + fluxo de ordens (super r√°pido)
‚îú‚îÄ‚îÄ envio_grafico_book.py    # Envia apenas: candle 1m + livro de ofertas (em menor frequ√™ncia)
‚îú‚îÄ‚îÄ conversa_manual.py       # Canal direto com o GPT para conversar como se fosse seu s√≥cio
‚îú‚îÄ‚îÄ ip.py                    # Verifica√ß√£o do IP atual e ativa√ß√£o de modo pausa autom√°tico se mudar
‚îú‚îÄ‚îÄ log_envio_gpt.json       # Espelho dos dados enviados pro GPT (debug)pra validar se esta indo os dados certos
‚îú‚îÄ‚îÄ memory_gpt.json          # Backup de contexto (mem√≥ria seletiva escrita pelo GPT)
‚îú‚îÄ‚îÄ log_conversa_manual.json # Hist√≥rico completo das conversas no terminal manual


---

üîÑ Sobre os JSONs enviados

Separa√ß√£o total, como o GPT sugeriu:

1. envio_fluxo.py

preco_atual

fluxo_ordens



2. envio_grafico_book.py

kline_1m

order_book




Isso permite controle de frequ√™ncia diferente por tipo de dado, melhora a assertividade e economiza tokens.


---

‚è± Frequ√™ncia dos dados (ms)

Os ms s√£o configur√°veis diretamente nos arquivos envio_fluxo.py e envio_grafico_book.py.

O GPT pode sugerir mudan√ßas de tempo, mas voc√™ aplica no c√≥digo manualmente (pelo menos por enquanto).

Nada muda sem sua aprova√ß√£o expl√≠cita.



---

üßë‚Äçüíª Sobre o main.py

√â fixo. N√£o √© tempor√°rio.

√â o n√∫cleo executor: recebe os dados e envia pro GPT decidir entrada/sa√≠da.

O GPT responde com algo como:

ENTRAR COMPRADO COM ORDEM MERCADO USANDO 23 USDT

Se n√£o for hora de entrar ou sair, o GPT fica em sil√™ncio.

Futuramente, ele controlar√° ordens reais (mercado, limit, stop limit).





üí¨ conversa_manual.py

Canal direto entre voc√™ e o GPT.

Serve pra:

Perguntar coisas: ‚ÄúQual ms ideal?‚Äù, ‚ÄúQual assertividade?‚Äù

GPT mandar mensagens espont√¢neas: ‚ÄúRecomendo reduzir o ms do fluxo.‚Äù


Possui vida pr√≥pria, com hist√≥rico em log_conversa_manual.json.

Pode ser usado pra informar saldo, pedir an√°lises, questionar decis√µes, etc.



---

üí∏ Sobre o valor da banca e gest√£o de risco

O GPT executor decidir√° quanto da banca usar por opera√ß√£o.

Pode usar tudo, parte, ou quase nada, baseado no risco e contexto da entrada.

O valor da banca pode ser informado por voc√™ no conversa_manual.py, e o GPT guardar√° no memory_gpt.json.

Nenhuma regra fixa de "1%" ou "sempre 10 USDT" ‚Äî a decis√£o √© sempre contextual.



---

üíæ memory_gpt.json

Mem√≥ria auxiliar persistente.

Escrito pelo GPT (com ou sem comando seu) com informa√ß√µes relevantes:

"Saldo atual: 150 USDT"

"Ativar modo conservador"

"√öltima opera√ß√£o: venda parcial"


Voc√™ pode apagar, editar ou restaurar como quiser.



---

üí¨ log_conversa_manual.json

Guarda tudo que foi conversado no terminal manual.

Tipo um WhatsApp: conversa bruta.

Pode ser apagado ou limpo manualmente.

Serve como hist√≥rico de an√°lise e auditoria.



---

üîê ip.py

Verifica o IP da sua conex√£o a cada 1 segundo.

Se o IP mudar (o que pode acontecer na sua internet din√¢mica), o sistema:

1. Pausa automaticamente a execu√ß√£o.


2. Exibe o novo IP no terminal, pra voc√™ atualizar r√°pido na Binance.


3. Toca alerta sonoro.


4. O GPT s√≥ manda mensagens administrativas.


5. Retoma opera√ß√£o somente quando voc√™ digitar "." ou "L" no terminal.




‚úÖ Garante que nenhuma ordem seja enviada com IP n√£o autorizado.


---

üîå Conex√£o real com a Binance

Atualmente em modo paper trading (testes manuais no TradingView).

Ap√≥s valida√ß√£o de assertividade, o sistema ser√° conectado √† API da Binance:

Chaves secretas protegidas.

Controle real de saldo, ordens e resposta em tempo real.


A gest√£o ainda ser√° 100% decidida pelo GPT.



---

Checklist finalizada. ‚úÖ
Tudo modular, claro, profissional e pronto pra dividir com outros chats.

import threading
import time
import json
from datetime import datetime, timezone
from queue import Queue
import requests
import winsound
import os
import openai
from utils_memory import exportar_memoria_texto
from utils_memoria_curta import carregar_memoria_curta, salvar_memoria_curta, apagar_da_memoria_curta

# ======== GPT CONFIG - API OFICIAL OPENAI ========
openai.api_key = os.getenv("OPENAI_API_KEY")
modelo = "gpt-4.1-mini-2025-04-14"

# ======== CACHE DAS MEM√ìRIAS (2 MINUTOS) ========
memoria_cache = ""
memoria_curta_cache = ""
ultima_atualizacao = 0

def atualizar_memorias():
    global memoria_cache, memoria_curta_cache, ultima_atualizacao
    agora = time.time()
    if agora - ultima_atualizacao >= 15:
        memoria_cache = exportar_memoria_texto()
        memoria_curta = carregar_memoria_curta()
        memoria_curta_cache = json.dumps(memoria_curta, indent=2, ensure_ascii=False)
        ultima_atualizacao = agora

# ======== LIMPEZA DE LOG GPT ========
def limpar_log_periodicamente(intervalo=50):
    while True:
        try:
            with open("log_envio_gpt.json", "w") as f:
                f.write("")
        except Exception as e:
            print(f"‚ùå Erro ao limpar o log: {e}")
        time.sleep(intervalo)

# ======== IMPORTANDO OS M√ìDULOS =========
from envio_fluxo import iniciar_fluxo
from envio_grafico_book import iniciar_grafico_book

# ======== FILAS =========
queue_fluxo = Queue()
queue_book = Queue()

modo_pausa = False
ip_atual = None

# ======== IP =========
def get_ip():
    try:
        return requests.get("https://api.ipify.org").text.strip()
    except:
        return None

def beep_infinito(parar_evento):
    while not parar_evento.is_set():
        winsound.Beep(1000, 500)
        time.sleep(0.2)

def monitorar_ip():
    global ip_atual, modo_pausa
    parar_beep = threading.Event()
    thread_beep = None

    while True:
        time.sleep(1)
        novo_ip = get_ip()
        if novo_ip is None:
            continue
        if ip_atual is None:
            ip_atual = novo_ip
            print(f"[IP] Inicial: {ip_atual}")
            continue
        if novo_ip != ip_atual:
            print(f"\n[‚ö†Ô∏è IP ALTERADO] {ip_atual} ‚Üí {novo_ip}")
            ip_atual = novo_ip
            modo_pausa = True
            if thread_beep is None or not thread_beep.is_alive():
                parar_beep.clear()
                thread_beep = threading.Thread(target=beep_infinito, args=(parar_beep,))
                thread_beep.start()
            print("Pressione ENTER para retomar...")
            input()
            parar_beep.set()
            thread_beep.join()
            modo_pausa = False
            print("‚úîÔ∏è Retomando opera√ß√£o...\n")

# ======== GPT ENVIO =========
def enviar_para_gpt(tipo, dados, incluir_memorias=True):
    try:
        mensagens = []

        if incluir_memorias:
            atualizar_memorias()
            prompt = {
                "role": "system",
                "content": (
                    "Abaixo est√£o instru√ß√µes e informa√ß√µes fixas do operador humano (memory_gpt.json):\n\n"
                    f"{memoria_cache}\n\n"
                    "Abaixo est√° a mem√≥ria tempor√°ria atual (memoria_curta_gpt.json), enviada como JSON real:\n\n"
                    f"{memoria_curta_cache}\n\n"
                    "Use essas informa√ß√µes para decidir se deve salvar novos dados ou apagar dados antigos da mem√≥ria curta. Responda sempre com {'salvar': {...}} ou {'apagar': [...]} quando for o caso."
                )
            }
            mensagens.append(prompt)

        mensagens.append({"role": "user", "content": json.dumps(dados)})

        response = openai.chat.completions.create(
            model=modelo,
            messages=mensagens,
            temperature=0.2
        )

        resposta_gpt = response.choices[0].message.content
        print(f"üß† GPT ({tipo.upper()}): {resposta_gpt.encode('utf-8', errors='replace').decode('utf-8')}")

        try:
            resposta_json = json.loads(resposta_gpt)
            if "salvar" in resposta_json:
                salvar_memoria_curta(resposta_json["salvar"])
                print("üíæ GPT salvou na mem√≥ria curta:", resposta_json["salvar"])
            if "apagar" in resposta_json:
                apagar_da_memoria_curta(resposta_json["apagar"])
                print("üóëÔ∏è GPT apagou da mem√≥ria curta:", resposta_json["apagar"])
        except:
            pass

        with open("log_envio_gpt.json", "a", encoding="utf-8") as f:
            json.dump({
                "tipo": tipo,
                "dados": dados,
                "timestamp_envio": datetime.now(timezone.utc).isoformat()
            }, f, indent=2, ensure_ascii=False)
            f.write("\n\n")

    except Exception as e:
        print("‚ùå Erro ao enviar para o GPT:", e)

# ‚úÖ ENVIO EXCLUSIVO DAS MEM√ìRIAS
def enviar_memorias_para_gpt():
    atualizar_memorias()
    dados_memorias = {
        "memory_gpt": memoria_cache,
        "memoria_curta_gpt": json.loads(memoria_curta_cache)
    }
    enviar_para_gpt("memorias", dados_memorias, incluir_memorias=False)

def loop_envio_memorias():
    while True:
        enviar_memorias_para_gpt()
        time.sleep(15)

# ======== MONITOR DE FILAS =========
def monitorar_filas():
    while True:
        if modo_pausa:
            time.sleep(1)
            continue

        if not queue_fluxo.empty():
            pacote = queue_fluxo.get()
            enviar_para_gpt(pacote["tipo"], pacote["dados"], incluir_memorias=False)

        if not queue_book.empty():
            pacote = queue_book.get()
            enviar_para_gpt(pacote["tipo"], pacote["dados"], incluir_memorias=False)

        time.sleep(0.01)

# ======== IN√çCIO =========
if __name__ == "__main__":
    print("üß† NeuroScalp MAIN rodando (API OpenAI, com mem√≥ria ativa)...\n")

    threading.Thread(target=iniciar_fluxo, args=(queue_fluxo,), daemon=True).start()
    threading.Thread(target=iniciar_grafico_book, args=(queue_book,), daemon=True).start()
    threading.Thread(target=monitorar_ip, daemon=True).start()
    threading.Thread(target=monitorar_filas, daemon=True).start()
    threading.Thread(target=limpar_log_periodicamente, daemon=True).start()
    threading.Thread(target=loop_envio_memorias, daemon=True).start()

    while True:
        time.sleep(1)